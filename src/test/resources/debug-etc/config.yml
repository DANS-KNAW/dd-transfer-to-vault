#
# dd-transfer-to-vault configuration file
#
server:
  applicationContextPath: /
  adminContextPath: /
  applicationConnectors:
    - type: http
      port: 20350
  adminConnectors:
    - type: http
      port: 20351
  # Logs the requests to the Jetty http server
  requestLog:
    appenders:
      - type: file
        archive: false
        timeZone: system
        currentLogFilename: data/request.log

transfer:
  ocflStorageRoot: Test Datastation
  # Inbox for incoming DVEs
  collectDve:
    nbnSource: OAI_ORE
    inbox:
      path: data/01_transfer-inbox/inbox
      pollingInterval: 500ms
    outbox:
      processed: data/02_extract-metadata/inbox
      failed: data/01_transfer-inbox/failed
  extractMetadata:
    inbox:
      path: data/02_extract-metadata/inbox
      pollingInterval: 500ms
    outbox:
      processed: data/03_send-to-vault/inbox
      failed: data/02_extract-metadata/outbox/failed
      rejected: data/02_extract-metadata/outbox/rejected
    taskQueue:
      nameFormat: "extract-metadata-worker-%d"
      maxQueueSize: 5000
      # Number of threads will be increased when maxQueueSize is exceeded.
      minThreads: 1
      # No more than maxThreads will be created though
      maxThreads: 3
      # Threads will die after 60 seconds of idleness
      keepAliveTime: 60 seconds
  sendToVault:
    inbox:
      path: data/03_send-to-vault/inbox
      pollingInterval: 500ms
    outbox:
      processed: data/03_send-to-vault/outbox/processed
      failed: data/03_send-to-vault/outbox/failed
    dataVault:
      # The current batch being assembled
      currentBatchWorkingDir: data/03_send-to-vault/work
      # If the batch size exceeds this threshold, move work to a new batch in the batchRoot and issue an import request
      batchThreshold: 1MB
      # Create import batches under this directory
      batchRoot: /home/janm/git/dans-core-systems/modules/dd-data-vault/data/ingest/inbox

  catalogBaseUrl: http://dev.catalog.vault.datastations.nl/dataset
  registrationInterval: 1000
  inbox:
    path: data/nbn-registration/inbox
    pollingInterval: 500ms
  outbox:
    processed: data/nbn-registration/outbox/processed
    failed: data/nbn-registration/outbox/failed
  gmh:
    url: https://resolver.tgharvester.dans.knaw.nl/gmh-registration-service/nbn
    token: # Fill in a valid token, generated via the token endpoint of the GMH server
    httpClient:
      timeout: 30s
      connectionTimeout: 15s
      timeToLive: 1h
      retries: 2
      # The GMH server does not handle GZIP compression
      gzipEnabled: false
      userAgent: dd-transfer-to-vault

vaultCatalog:
  url: http://dev.transfer.dans-data.nl:20305
  httpClient:
    timeout: 10s
    connectionTimeout: 1min
    # disable chunked encoding because it breaks the multipart/form-data headers:
    chunkedEncodingEnabled: false
    timeToLive: 1h
    cookiesEnabled: false
    maxConnections: 128
    maxConnectionsPerRoute: 128
    keepAlive: 0ms
    retries: 0
    userAgent: dd-transfer-to-vault

dataVault:
  url: http://localhost:20365
  httpClient:
    timeout: 10s
    connectionTimeout: 1min
    # disable chunked encoding because it breaks the multipart/form-data headers:
    chunkedEncodingEnabled: false
    timeToLive: 1h
    cookiesEnabled: false
    maxConnections: 128
    maxConnectionsPerRoute: 128
    keepAlive: 0ms
    retries: 0
    userAgent: dd-transfer-to-vault

#
# See https://www.dropwizard.io/en/latest/manual/configuration.html#logging
#
logging:
  level: INFO
  appenders:
    - type: file
      archive: false
      timeZone: system
      currentLogFilename: data/dd-transfer-to-vault.log
    - type: console
      # Used in combination with journald, which already adds the timestamp
      logFormat: "%-5p %c{0}: %m%n%dwREx"
  loggers:
    'org.hibernate.engine.internal.StatisticalLoggingSessionEventListener': 'OFF'
    'nl.knaw.dans.transfer.core.RemoveXmlFilesTask': 'OFF'
    'nl.knaw.dans.transfer.core.RemoveEmptyTargetDirsTask': 'OFF'
