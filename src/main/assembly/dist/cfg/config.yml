server:
  applicationContextPath: /
  adminContextPath: /
  applicationConnectors:
    - type: http
      port: 20350
  adminConnectors:
    - type: http
      port: 20351

health:
  delayedShutdownHandlerEnabled: false
  initialOverallState: false
  healthChecks:
    - name: Inbox
      critical: true
      initialState: false
      schedule:
        checkInterval: 60s
    - name: Filesystem
      critical: true
      initialState: false
      schedule:
        checkInterval: 60s
    - name: Partitions
      critical: true
      initialState: false
      schedule:
        checkInterval: 60s

collect:
  inboxes: [ ]
  # polling interval in milliseconds
  pollingInterval: 500
  # timeout for inbox health check in seconds
  canReadTimeout: 5
  taskQueue:
    nameFormat: "collect-worker-%d"
    maxQueueSize: 5000
    # Number of threads will be increased when maxQueueSize is exceeded.
    minThreads: 1
    # No more than maxThreads will be created though
    maxThreads: 10
    # Threads will die after 60 seconds of idleness
    keepAliveTime: 60 seconds

extractMetadata:
  inbox: /var/opt/dans.knaw.nl/tmp/metadata-inbox
  # polling interval in milliseconds
  pollingInterval: 500
  taskQueue:
    nameFormat: "extract-metadata-worker-%d"
    maxQueueSize: 5000
    # Number of threads will be increased when maxQueueSize is exceeded.
    minThreads: 1
    # No more than maxThreads will be created though
    maxThreads: 10
    # Threads will die after 60 seconds of idleness
    keepAliveTime: 60 seconds

sendToVault:
  inbox: /var/opt/dans.knaw.nl/tmp/send-to-vault-inbox
  pollingInterval: 500
  work: /var/opt/dans.knaw.nl/tmp/send-to-vault-work
  maxBatchSize: 100000000
  outbox: /var/opt/dans.knaw.nl/tmp/data-vault/inbox

confirmArchived:
  cron: '0 0 * * * ?' # cron expression for triggering a polling round
  # TODO: move complete vaultCatalog block to here, deduplicate definition of url.
  vaultServiceEndpoint: http://localhost:20305
  taskQueue:
    nameFormat: "confirm-archived-worker-%d"
    maxQueueSize: 5000
    # Number of threads will be increased when maxQueueSize is exceeded.
    minThreads: 1
    # No more than maxThreads will be created though
    maxThreads: 10
    # Threads will die after 60 seconds of idleness
    keepAliveTime: 60 seconds

vaultCatalog:
  url: http://localhost:20305
  httpClient:
    timeout: 10s
    connectionTimeout: 1min
    # disable chunked encoding because it breaks the multipart/form-data headers:
    chunkedEncodingEnabled: false
    timeToLive: 1h
    cookiesEnabled: false
    maxConnections: 128
    maxConnectionsPerRoute: 128
    keepAlive: 0ms
    retries: 0
    userAgent: dd-transfer-to-vault

dataVault:
  url: http://localhost:20365
  httpClient:
    timeout: 10s
    connectionTimeout: 1min
    # disable chunked encoding because it breaks the multipart/form-data headers:
    chunkedEncodingEnabled: false
    timeToLive: 1h
    cookiesEnabled: false
    maxConnections: 128
    maxConnectionsPerRoute: 128
    keepAlive: 0ms
    retries: 0
    userAgent: dd-transfer-to-vault


database:
  driverClass: org.postgresql.Driver
  url: jdbc:postgresql://localhost:5432/dd_transfer_to_vault
  user: changeme
  password: changeme
  logValidationErrors: true
  properties:
    hibernate.dialect: 'org.hibernate.dialect.PostgreSQL95Dialect'
    hibernate.hbm2ddl.auto: update

logging:
  level: INFO
  appenders:
    - archive: false
      type: file
      timeZone: system
      currentLogFilename: '/var/opt/dans.knaw.nl/log/dd-transfer-to-vault/dd-transfer-to-vault.log'
  loggers:
    'org.hibernate.engine.internal.StatisticalLoggingSessionEventListener': 'OFF'
