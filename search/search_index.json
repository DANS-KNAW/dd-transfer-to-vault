{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"dd-transfer-to-vault \u00b6 Processes dataset version exports for inclusion in the DANS Data Vault Purpose \u00b6 This service is responsible for taking dataset version exports (DVE for short), cataloging them and transferring them to the DANS data vault. If the dataset version export is the first version of a dataset, an NBN persistent identifier is minted for the dataset and registered in the NBN database. Interfaces \u00b6 This service has the following interfaces: Provided interfaces \u00b6 Inbox \u00b6 Protocol type : Shared filesystem Internal or external : internal Purpose : to receive DVEs from the Data Stations and other services Admin console \u00b6 Protocol type : HTTP Internal or external : internal Purpose : application monitoring and management Consumed interfaces \u00b6 Data Vault Catalog \u00b6 Protocol type : HTTP Internal or external : internal Purpose : to maintain information about the datasets and their versions that are stored in the DANS data vault NBN Database \u00b6 Protocol type : HTTP Internal or external : external Purpose : to mint and register NBN persistent identifiers for datasets Data Vault import inbox \u00b6 Protocol type : Shared filesystem Internal or external : internal Purpose : to import DVEs into the DANS data vault Data Vault API \u00b6 Protocol type : HTTP Internal or external : internal Purpose : to issue commands to the DANS data vault and retrieve information from it Processing \u00b6 This service is best viewed as a processing pipeline for DVEs. It connects a source that produces DVEs to a target DANS Data Vault Storage Root , which stores the DVEs as OCFL object versions. A source can be a Data Station or a Vault as a Service client. The service takes care of cataloging the DVEs and ensuring that the dataset is resolvable via the NBN persistent identifier. It attempts to do this in an efficient way, by processing multiple DVEs in parallel, while ensuring that the order of the dataset version exports is preserved. Furthermore, the service will attempt to resume processing of DVEs that were left unfinished in the event of a crash or restart. Inbox \u00b6 The inbox is a directory into which DVEs are dropped. When a DVE is detected the inbox will determine what the NBN of the target dataset is. DVEs for the same dataset version are processed in order, but DVEs for different dataset versions can be processed in parallel, except for the transfer to the vault (see below). Validation \u00b6 The first step in the processing pipeline is to validate the DVE. Currently, the only layout that is supported is the bagpack layout. If the DVE is not a bagpack, it will be rejected. Any other DVEs for the same dataset version will be blocked from processing until the problem is resolved. Metadata extraction \u00b6 The next step is to extract the metadata from the DVE and to create or update the dataset version in the DANS data vault catalog. The main source of metadata is the metadata/oai-ore.jsonld file in the DVE. NBN registration \u00b6 After the Vault Catalog has been updated, the NBN persistent identifier is minted and scheduled for registration in the NBN database. This is done in a separate background thread which uses a database table as a queue, so that the registration can be retried in case of a restart or crash. Transfer to vault \u00b6 Finally, the DVE is extracted to the current DANS data vault import inbox batch for this instance of dd-transfer-to-vault . If the size of the batch exceeds a configured threshold, the service will issue a command to the DANS data vault to import the current batch of DVEs. This step is executed on a single dedicated thread, so that determining the size of the batch can be done reliably.","title":"Description"},{"location":"#dd-transfer-to-vault","text":"Processes dataset version exports for inclusion in the DANS Data Vault","title":"dd-transfer-to-vault"},{"location":"#purpose","text":"This service is responsible for taking dataset version exports (DVE for short), cataloging them and transferring them to the DANS data vault. If the dataset version export is the first version of a dataset, an NBN persistent identifier is minted for the dataset and registered in the NBN database.","title":"Purpose"},{"location":"#interfaces","text":"This service has the following interfaces:","title":"Interfaces"},{"location":"#provided-interfaces","text":"","title":"Provided interfaces"},{"location":"#inbox","text":"Protocol type : Shared filesystem Internal or external : internal Purpose : to receive DVEs from the Data Stations and other services","title":"Inbox"},{"location":"#admin-console","text":"Protocol type : HTTP Internal or external : internal Purpose : application monitoring and management","title":"Admin console"},{"location":"#consumed-interfaces","text":"","title":"Consumed interfaces"},{"location":"#data-vault-catalog","text":"Protocol type : HTTP Internal or external : internal Purpose : to maintain information about the datasets and their versions that are stored in the DANS data vault","title":"Data Vault Catalog"},{"location":"#nbn-database","text":"Protocol type : HTTP Internal or external : external Purpose : to mint and register NBN persistent identifiers for datasets","title":"NBN Database"},{"location":"#data-vault-import-inbox","text":"Protocol type : Shared filesystem Internal or external : internal Purpose : to import DVEs into the DANS data vault","title":"Data Vault import inbox"},{"location":"#data-vault-api","text":"Protocol type : HTTP Internal or external : internal Purpose : to issue commands to the DANS data vault and retrieve information from it","title":"Data Vault API"},{"location":"#processing","text":"This service is best viewed as a processing pipeline for DVEs. It connects a source that produces DVEs to a target DANS Data Vault Storage Root , which stores the DVEs as OCFL object versions. A source can be a Data Station or a Vault as a Service client. The service takes care of cataloging the DVEs and ensuring that the dataset is resolvable via the NBN persistent identifier. It attempts to do this in an efficient way, by processing multiple DVEs in parallel, while ensuring that the order of the dataset version exports is preserved. Furthermore, the service will attempt to resume processing of DVEs that were left unfinished in the event of a crash or restart.","title":"Processing"},{"location":"#inbox_1","text":"The inbox is a directory into which DVEs are dropped. When a DVE is detected the inbox will determine what the NBN of the target dataset is. DVEs for the same dataset version are processed in order, but DVEs for different dataset versions can be processed in parallel, except for the transfer to the vault (see below).","title":"Inbox"},{"location":"#validation","text":"The first step in the processing pipeline is to validate the DVE. Currently, the only layout that is supported is the bagpack layout. If the DVE is not a bagpack, it will be rejected. Any other DVEs for the same dataset version will be blocked from processing until the problem is resolved.","title":"Validation"},{"location":"#metadata-extraction","text":"The next step is to extract the metadata from the DVE and to create or update the dataset version in the DANS data vault catalog. The main source of metadata is the metadata/oai-ore.jsonld file in the DVE.","title":"Metadata extraction"},{"location":"#nbn-registration","text":"After the Vault Catalog has been updated, the NBN persistent identifier is minted and scheduled for registration in the NBN database. This is done in a separate background thread which uses a database table as a queue, so that the registration can be retried in case of a restart or crash.","title":"NBN registration"},{"location":"#transfer-to-vault","text":"Finally, the DVE is extracted to the current DANS data vault import inbox batch for this instance of dd-transfer-to-vault . If the size of the batch exceeds a configured threshold, the service will issue a command to the DANS data vault to import the current batch of DVEs. This step is executed on a single dedicated thread, so that determining the size of the batch can be done reliably.","title":"Transfer to vault"},{"location":"config/","text":"Configuration \u00b6 This module can be configured by editing the configuration file. This file is installed in /etc/opt/dans.knaw.nl/dd-transfer-to-vault/config.yml when using the RPM. The settings are explained with comments in the file itself. An on-line version of the latest configuration file can be found here .","title":"Configuration"},{"location":"config/#configuration","text":"This module can be configured by editing the configuration file. This file is installed in /etc/opt/dans.knaw.nl/dd-transfer-to-vault/config.yml when using the RPM. The settings are explained with comments in the file itself. An on-line version of the latest configuration file can be found here .","title":"Configuration"},{"location":"context/","text":"Context \u00b6 This module is a component in the DANS Data Station Architecture .","title":"Context"},{"location":"context/#context","text":"This module is a component in the DANS Data Station Architecture .","title":"Context"},{"location":"dev/","text":"Development \u00b6 General information about developing DANS modules can be found here .","title":"Overview"},{"location":"dev/#development","text":"General information about developing DANS modules can be found here .","title":"Development"},{"location":"installation/","text":"Installation \u00b6 Currently, this project is built as an RPM package for RHEL8 and later. The RPM will install the binaries to /opt/dans.knaw.nl/dd-transfer-to-vault and the configuration files to /etc/opt/dans.knaw.nl/dd-transfer-to-vault . For installation on systems that do no support RPM and/or systemd: Build the tarball (see next section). Extract it to some location on your system, for example /opt/dans.knaw.nl/dd-transfer-to-vault . Start the service with the following command /opt/dans.knaw.nl/dd-transfer-to-vault/bin/dd-transfer-to-vault server /opt/dans.knaw.nl/dd-transfer-to-vault/cfg/config.yml Building from source \u00b6 Prerequisites: Java 17 or higher Maven 3.3.3 or higher RPM (optional, only if you want to build the RPM package) Steps: git clone https://github.com/DANS-KNAW/dd-transfer-to-vault.git cd dd-transfer-to-vault mvn clean install If the rpm executable is found at /usr/local/bin/rpm , the build profile that includes the RPM packaging will be activated. If rpm is available, but at a different path, then activate it by using Maven's -P switch: mvn -Pprm install . Alternatively, to build the tarball execute: mvn clean install assembly:single","title":"Installation"},{"location":"installation/#installation","text":"Currently, this project is built as an RPM package for RHEL8 and later. The RPM will install the binaries to /opt/dans.knaw.nl/dd-transfer-to-vault and the configuration files to /etc/opt/dans.knaw.nl/dd-transfer-to-vault . For installation on systems that do no support RPM and/or systemd: Build the tarball (see next section). Extract it to some location on your system, for example /opt/dans.knaw.nl/dd-transfer-to-vault . Start the service with the following command /opt/dans.knaw.nl/dd-transfer-to-vault/bin/dd-transfer-to-vault server /opt/dans.knaw.nl/dd-transfer-to-vault/cfg/config.yml","title":"Installation"},{"location":"installation/#building-from-source","text":"Prerequisites: Java 17 or higher Maven 3.3.3 or higher RPM (optional, only if you want to build the RPM package) Steps: git clone https://github.com/DANS-KNAW/dd-transfer-to-vault.git cd dd-transfer-to-vault mvn clean install If the rpm executable is found at /usr/local/bin/rpm , the build profile that includes the RPM packaging will be activated. If rpm is available, but at a different path, then activate it by using Maven's -P switch: mvn -Pprm install . Alternatively, to build the tarball execute: mvn clean install assembly:single","title":"Building from source"}]}